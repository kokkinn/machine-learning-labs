{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4008e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Adapted from lstm_text_generation.py in keras/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e39e9a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 10:09:20.494418: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from urllib import request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe36dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepairing data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepairing data \n",
    "print('Prepairing data...\\n')\n",
    "url = 'https://gist.githubusercontent.com/phillipj/4944029/raw/75ba2243dd5ec2875f629bf5d79f6c1e4b5a8b46/alice_in_wonderland.txt'\n",
    "text = request.urlopen(url).read().decode('utf8')\n",
    "\n",
    "# regex cleaning \n",
    "pattern1 = re.compile(r'[*\\[\\]â€™\\'\\\"`\\)\\(\\--]')\n",
    "pattern2 = re.compile(r'\\s{1,}')\n",
    "text = re.sub(pattern1, '', text)\n",
    "text = re.sub(pattern2, ' ', text)\n",
    "\n",
    "word_tokens = nltk.word_tokenize(text.lower())[0:5000] # is a list with all the words from a text \n",
    "# print(word_tokens)\n",
    "# print(sentense_tokens)\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0602d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # frequency of words without removing stop words\n",
    "\n",
    "# freq = nltk.FreqDist(word_tokens)\n",
    "\n",
    "# plt.xticks(fontsize=6, rotation=90)\n",
    "# plt.grid()\n",
    "# plt.title('Frequency of some words', size=15)\n",
    "# freq.plot(80,cumulative=False, show=False)\n",
    "# plt.savefig('images/word_freq_with_stop_words.png', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a70f523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# more filtering\n",
    "\n",
    "print('Filtering data...\\n')\n",
    "# removing stop words\n",
    "# stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "# stop_words.update([\",\", \".\", \":\", \";\", \"?\", \"!\", '*', '--', '[', ']', '``', '\\\"\\\"', \"\\'\\'\"])\n",
    "# word_tokens = [token for token in word_tokens if token not in stop_words] # words without stop words\n",
    "# print(word_tokens)\n",
    "\n",
    "\n",
    "# # lematization\n",
    "# lemmatizer = nltk.WordNetLemmatizer()\n",
    "# word_tokens = [lemmatizer.lemmatize(token.lower()) for token in word_tokens]\n",
    "# # print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365f0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # frequency of words with stop words removing\n",
    "\n",
    "# freq = nltk.FreqDist(word_tokens)\n",
    "# plt.xticks(fontsize=6, rotation=90)\n",
    "# plt.grid()\n",
    "# plt.title('Frequency of some words', size=15)\n",
    "# freq.plot(80,cumulative=False, show=False)\n",
    "# plt.savefig('images/word_freq_without_stop_words.png', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b09ff248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags meaning parser\n",
    "\n",
    "dict_tags_meaning = dict()\n",
    "url = 'https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html'\n",
    "response = requests.get(url, 'html_parser')\n",
    "soup = BeautifulSoup(response.content)\n",
    "for child in list(soup.table.children)[2:]:\n",
    "    if isinstance(child, NavigableString):\n",
    "        continue\n",
    "    dict_tags_meaning[child.find_all('td')[1].text.strip()] = child.find_all('td')[2].text.strip()\n",
    "# print(dict_tags_meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0626cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags analyzis\n",
    "\n",
    "# df_tags = pd.DataFrame(nltk.pos_tag(word_tokens), columns=['Word', 'Tag'])\n",
    "\n",
    "# ser_tags_grouping = df_tags['Tag'].value_counts()\n",
    "# ser_tags_grouping.rename(index=dict_tags_meaning, inplace=True)\n",
    "# # print(ser_tags_grouping)\n",
    "# plt.xticks(fontsize=10, rotation=90)\n",
    "# plt.grid()\n",
    "# plt.title('Frequency of tags', size=15)\n",
    "# plt.plot(ser_tags_grouping)\n",
    "# plt.savefig('images/tags_freq.png', bbox_inches = \"tight\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d50a8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizing data\n",
    "\n",
    "print('Tokenizing data...\\n')\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(word_tokens)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "# tokenizer.word_index # is a dictionary with unique words and their numeric values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9da34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(word_tokens).replace(' ,', ',').replace(' .', '.').replace(' :', ':').replace(' ?', '?').replace(' ;', ';').replace('wa', 'was')\n",
    "# print(text)\n",
    "sentense_tokens = nltk.sent_tokenize(text) # is a list with all the sentenses from a text\n",
    "input_sequences = []\n",
    "for line in sentense_tokens:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = to_categorical(labels, num_classes=total_words)\n",
    "\n",
    "# pd.DataFrame(input_sequences).to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b5dd9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating lookup tables\n",
    "\n",
    "# print('Creating lookup tables...\\n')\n",
    "# set_chars = set([c for c in text])\n",
    "# nb_chars = len(chars)\n",
    "# char2index = dict((c, i) for i, c in enumerate(set_chars))\n",
    "# index2char = dict((i, c) for i, c in enumerate(set_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ecb45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Creating input and label text...\")\n",
    "# SEQLEN = 10\n",
    "# STEP = 1\n",
    "\n",
    "# input_chars = []\n",
    "# label_chars = []\n",
    "# for i in range(0, len(text) - SEQLEN, STEP):\n",
    "#     input_chars.append(text[i:i + SEQLEN])\n",
    "#     label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b52e8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vectorize the input and label chars\n",
    "# # Each row of the input is represented by seqlen characters, each\n",
    "# # represented as a 1-hot encoding of size len(char). There are\n",
    "# # len(input_chars) such rows, so shape(X) is (len(input_chars),\n",
    "# # seqlen, nb_chars).\n",
    "# # Each row of output is a single character, also represented as a\n",
    "# # dense encoding of size len(char). Hence shape(y) is (len(input_chars),\n",
    "# # nb_chars).\n",
    "\n",
    "# print(\"Vectorizing input and label text...\")\n",
    "# X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "# y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "# for i, input_char in enumerate(input_chars):\n",
    "#     for j, ch in enumerate(input_char):\n",
    "#         X[i, j, char2index[ch]] = 1\n",
    "#     y[i, char2index[label_chars[i]]] = 1\n",
    "# np.zeros(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c70dc460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "126/126 [==============================] - 36s 231ms/step - loss: 6.3452\n",
      "Epoch 2/30\n",
      "126/126 [==============================] - 25s 199ms/step - loss: 6.0235\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 25s 200ms/step - loss: 5.9853\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 5.9194\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 26s 209ms/step - loss: 5.8362\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 25s 200ms/step - loss: 5.7879\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 25s 199ms/step - loss: 5.7621\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 25s 200ms/step - loss: 5.6760\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 25s 200ms/step - loss: 5.5761\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 5.4687\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 33s 258ms/step - loss: 5.3758\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 69s 552ms/step - loss: 5.2686\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 51s 401ms/step - loss: 5.1756\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 32s 254ms/step - loss: 5.0635\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 32s 252ms/step - loss: 4.9790\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 30s 237ms/step - loss: 4.8655\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 26s 208ms/step - loss: 4.7679\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 25s 201ms/step - loss: 4.6528\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 30s 241ms/step - loss: 4.5513\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 61s 489ms/step - loss: 4.4307\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 71s 545ms/step - loss: 4.3162\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 33s 266ms/step - loss: 4.2298\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 35s 279ms/step - loss: 4.1112\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 35s 278ms/step - loss: 4.0778\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 34s 269ms/step - loss: 3.9256\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 40s 316ms/step - loss: 3.8637\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 34s 268ms/step - loss: 3.7525\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 33s 260ms/step - loss: 3.6256\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 45s 361ms/step - loss: 3.5087\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 41s 316ms/step - loss: 3.4085\n"
     ]
    }
   ],
   "source": [
    "# # Build the model. We use a single RNN with a fully connected layer\n",
    "# # to compute the most likely predicted output char\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "model = Sequential()v\n",
    "model.add(SimpleRNN(500, return_sequences=False, input_shape=(max_sequence_len-1, 1), unroll=True))\n",
    "model.add(Dense(total_words))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "history = model.fit(xs, ys, epochs=30, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaaf6565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "973"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # We train the model in batches and test output generated at each step\n",
    "# for iteration in range(NUM_ITERATIONS):\n",
    "#     print(\"=\" * 50)\n",
    "#     print(\"Iteration #: %d\" % (iteration))\n",
    "#     model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "#     # testing model\n",
    "#     # randoml       y choose a row from input_chars, then use it to\n",
    "#     # generate text from model for next 100 chars\n",
    "#     test_idx = np.random.randint(len(input_chars))\n",
    "#     test_chars = input_chars[test_idx]\n",
    "#     print(\"Generating from seed: %s\" % (test_chars))\n",
    "#     print(test_chars, end=\"\")\n",
    "#     for i in range(NUM_PREDS_PER_EPOCH):\n",
    "#         Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "#         for i, ch in enumerate(test_chars):\n",
    "#             Xtest[0, i, char2index[ch]] = 1\n",
    "#         pred = model.predict(Xtest, verbose=0)[0]\n",
    "#         ypred = index2char[np.argmax(pred)]\n",
    "#         print(ypred, end=\"\")\n",
    "#         # move forward with test_chars + ypred\n",
    "#         test_chars = test_chars[1:] + ypred\n",
    "#     print()\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cfcd9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 10:09:32.190805: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Dimension value must be integer or None or have an __index__ method, got value '486.5' with type '<class 'float'>'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [16], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m Sequential()\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mEmbedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_words\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_words\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_sequence_len\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39madd(Bidirectional(LSTM(\u001B[38;5;241m150\u001B[39m, return_sequences \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m)))\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39madd(Dense(total_words, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msoftmax\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001B[0m, in \u001B[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_setattr_tracking \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 205\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    207\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_setattr_tracking \u001B[38;5;241m=\u001B[39m previous_value  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Dimension value must be integer or None or have an __index__ method, got value '486.5' with type '<class 'float'>'"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(total_words, total_words/2, input_length=max_sequence_len-1))\n",
    "# model.add(Bidirectional(LSTM(150, return_sequences = False)))\n",
    "# model.add(Dense(total_words, activation='softmax'))\n",
    "# adam = Adam(learning_rate=0.01)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "# history = model.fit(xs, ys, epochs=15, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['accuracy']\n",
    "# loss = history.history['loss']\n",
    "# epochs = range(len(acc))\n",
    "# plt.plot(epochs, acc)\n",
    "# plt.title('Training accuracy')\n",
    "# plt.savefig('images/model_acc.png', bbox_inches='tight')\n",
    "# plt.plot(epochs, loss, 'b')\n",
    "# plt.title('Training loss')\n",
    "\n",
    "# plt.savefig('images/model_loss.png')\n",
    "\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eba403",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"down the\"\n",
    "next_words = 20\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
    "\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break \n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e518a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
